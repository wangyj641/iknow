{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbfe3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54749174",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "401 Unauthorized\n",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 401 Unauthorized",
      "",
      "    at APIError.generate (file:///C:/Users/wangy/AppData/Local/deno/npm/registry.npmjs.org/openai/4.104.0/error.mjs:44:20)",
      "    at OpenAI.makeStatusError (file:///C:/Users/wangy/AppData/Local/deno/npm/registry.npmjs.org/openai/4.104.0/core.mjs:295:25)",
      "    at OpenAI.makeRequest (file:///C:/Users/wangy/AppData/Local/deno/npm/registry.npmjs.org/openai/4.104.0/core.mjs:339:30)",
      "    at eventLoopTick (ext:core/01_core.js:179:7)",
      "    at async file:///C:/Users/wangy/AppData/Local/deno/npm/registry.npmjs.org/@langchain/openai/0.0.22/dist/chat_models.js:668:29",
      "    at async RetryOperation._fn (file:///C:/Users/wangy/AppData/Local/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const llm = new ChatOpenAI({\n",
    "  apiKey: process.env.GITHUB_TOKEN, // PAT 需包含 models:read\n",
    "  configuration: { baseURL: \"https://models.github.ai/inference\" }, // ← 重点：无 /v1\n",
    "  model: \"openai/gpt-4o-mini\",\n",
    "  temperature: 0.2,\n",
    "});\n",
    "\n",
    "const res = await llm.invoke([new HumanMessage(\"用中文讲个冷笑话\")]);\n",
    "res.content;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const llm = new ChatOpenAI({\n",
    "  apiKey: process.env.GITHUB_TOKEN, // PAT 需包含 models:read\n",
    "  model: \"openai/gpt-4o-mini\", // ✅ 带 publisher 前缀，示例见下\n",
    "  temperature: 0.2,\n",
    "  configuration: {\n",
    "    baseURL: \"https://models.github.ai/inference\",\n",
    "    // 如需，可加自定义头：X-GitHub-Api-Version: 2022-11-28（可选）\n",
    "    // defaultHeaders: { \"X-GitHub-Api-Version\": \"2022-11-28\" }  // 仅当你的 OpenAI 客户端支持\n",
    "  },\n",
    "});\n",
    "\n",
    "const res = await llm.invoke([new HumanMessage(\"用中文讲个冷笑话\")]);\n",
    "res.content;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
